{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install gensim nltk spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import es_core_news_sm\n",
    "import gensim\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import unidecode\n",
    "import re\n",
    "\n",
    "#for bigrams\n",
    "from gensim.models import Phrases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/carme/Dropbox/MIO/DOCS/Hertie/Thesis/Hertie-Thesis/Data/clean_data.csv')\n",
    "# 'C:/Users/carme/Dropbox/MIO/DOCS/Hertie/Thesis/Elecciones_Municipales_2024/clean_data.csv'\n",
    "#filter column with na values\n",
    "plans = data.copy().dropna()\n",
    "plans = plans.reset_index(drop=True)\n",
    "#plans.shape\n",
    "\n",
    "# Encontrar duplicados en 'clean_text'\n",
    "duplicated_texts = plans['clean_text'][plans['clean_text'].duplicated(keep=False)]\n",
    "\n",
    "# Mostrar los documentos duplicados\n",
    "# print(duplicated_texts)\n",
    "\n",
    "# plans.loc[303,'clean_text']\n",
    "plans.at[303,'clean_text'] = float(\"NaN\")\n",
    "# plans.loc[303,'clean_text']\n",
    "plans = plans.dropna()\n",
    "# Ensure all entries in 'clean_text' are strings and handle missing values\n",
    "data['clean_text'] = data['clean_text'].fillna('').astype(str)\n",
    "plans.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIN BIGRAMS y sin stop words\n",
    "# # Load the Spanish NLP model\n",
    "# nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "# # Preprocess documents: tokenize, remove stopwords and punctuation, and lemmatize\n",
    "# def preprocess(doc):\n",
    "#     spacy_doc = nlp(doc.lower())\n",
    "#     return [token.lemma_ for token in spacy_doc if not token.is_stop and not token.is_punct]\n",
    "\n",
    "# processed_docs = data['clean_text'].apply(preprocess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\carme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# CON BIGRAMS\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('spanish'))  # Using Spanish stopwords\n",
    "\n",
    "# Tokenize documents\n",
    "def preprocess(text):\n",
    "    # Convert to lower case and remove accents\n",
    "    text = text.lower()\n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = [word for word in text.split() if word not in stop_words]\n",
    "    tokens = [unidecode.unidecode(word) for word in tokens]\n",
    "    return tokens\n",
    "\n",
    "tokenized_docs = [preprocess(doc) for doc in plans['clean_text']]\n",
    "\n",
    "# Build bigrams\n",
    "bigram = Phrases(tokenized_docs, min_count=1, threshold=2) # Play with these parameters according to your specific needs\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "# Apply the trained bigram model to each document\n",
    "docs_with_bigrams = [bigram_mod[doc] for doc in tokenized_docs]\n",
    "\n",
    "# Create a dictionary representation of the documents\n",
    "dictionary = Dictionary(docs_with_bigrams)\n",
    "\n",
    "# Create a corpus from the dictionary and tokenized documents\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs_with_bigrams]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predefined topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define seed words for topics, should be tops bigrams\n",
    "seed_words = {\n",
    "    'Seguridad': ['seguridad', 'homicidio', 'asaltos','policia','hurto','hurtos','robo','robos','tacha'],\n",
    "    'Capital Social': ['abstencionismo', 'participacion elecciones'],\n",
    "    'Transformacion Digital': ['digital','gobernanza datos','municipalidad electronica', 'e municipalidad', ], #muni electronica y e muni son de los tramites, pero son digital, segun yo no deberian ir aca?\n",
    "    'Tramites Simples': ['plan de mejora regulatoria','permiso de construccion','permisos de construccion','uso de suelos'],\n",
    "    'Transparencia Municipal': ['transparencia','denuncia','acceso informacion','rendicion cuentas','participacion ciudadana','datos abiertos'],\n",
    "    'Administracion Presupuestaria': ['presupuesto','ejecucion recursos','morosidad','dependencia financiera'],\n",
    "    #'Compromiso con la sostenibilidad': ['residuos recolectados','basura','residuos','reciclaje','valoracion residuos','medio ambiente','sostenibilidad'], #estas dos ultimas creo que deberia estar en otra categoria y deberia ser solo de recoleccion de residuos\n",
    "    #lo voy a dividir en dos:\n",
    "    'Recoleccion de Residuos':['residuos','reciclaje'],\n",
    "    'Medio Ambiente':['medio ambiente','sostenibilidad'],\n",
    "    'Infraestructura de Transporte': ['red vial','vias','obras','infraestructura transporte','km','kilometro'],\n",
    "    'Conectividad Vial': ['conectividad vial','traslado','earopuerto','puerto','presas','atraso carretera'],\n",
    "    'Acceso a Servicios Publicos': ['agua','potable','tuberia','acueducto','electricidad','eliminacion de excremento'], #no inclui acceso a camion recolector de basura\n",
    "    'Servicios Publicos Municipales': ['inversion servicios','servicios municipales','servicios publicos','aseo vias','aseo sitios'], #no estoy incluyendo inversion en cultura, deporte y educacion\n",
    "    'Redes de Datos (internet)': ['datos moviles','velocidad descarga'], #no inclui 3g y 4g \n",
    "    'Redes de Voz Movil (telefonia)': ['telefonia','telefonica','llamadas telefonicas'], #no inclui 2g y 3g\n",
    "    'Redes de Datos Fijas (internet)': ['banda ancha','operadoras internet'],\n",
    "    'Acceso a TICs en Hogares': ['acceso computadoras','acceso internet'],\n",
    "    'Acceso a TICs en el Sistema Educativo': ['estudiantes computadora','pronie'],\n",
    "    'Salud': ['esperanza vida','mortalidad infantil','fertilidad adolescentes'],\n",
    "    'Escolaridad Media de Fuerza Laboral Actual': ['escolaridad','secundaria concluida'],\n",
    "    'Habilidades Tecnicas de Fuerza Laboral Actual': ['tecnicos graduados'],\n",
    "    #habilidades y competencias podria ser uno solo\n",
    "    'Habilidades en Ciencia y Tecnologia de Fuerza Laboral Actual': ['ciencia tecnologia','ingenieria tecnologia','ciencias medicas','ciencias exactas','ciencias naturales','ciencias agricolas'],\n",
    "    'Cobertura Educativa': ['alumnos','educacion primaria','educacion secundaria'],\n",
    "    'Curriculo Completo': ['ingles','curriculo completo'], #deje afuera informatica\n",
    "    'Competencias Basicas': ['matematica','espanol','evaluacion estandarizada','segundo idioma'], #deje afuera cientifica y secundaria\n",
    "    'Encadenamientos Productivos': ['encadenamientos productivos','relacion venta','relacion compra'],\n",
    "    'Produccion': ['pib capita','pib per capita','actividades economicas','actividad economica','emprendimiento'], #agregue emprendimiento\n",
    "    'Exportacion de Bienes': ['exportaciones','productos primarios'],\n",
    "    'Sector Constructivo': ['construcciones','construccion'],\n",
    "    'Sector Electrico': ['interrupciones electricas','electricidad','electrico'],\n",
    "    'Sector Laboral': ['desempleo','empleo','asalariado','asalariada','asegurado independiente'],\n",
    "    'Genero':['brecha','genero','mujeres','mujer','desigualdad'], #revisar desigualdad\n",
    "    'Cultura': ['cultura','recreacion','arte'],\n",
    "    'Deporte':['deporte'],\n",
    "    'Turismo': ['turismo','turistas']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Boost seed words by repeating them in the documents (optional step)\n",
    "# boosted_documents = []\n",
    "# for doc in processed_docs:\n",
    "#     boosted_doc = doc[:]\n",
    "#     for topic, seeds in seed_words.items():\n",
    "#         for seed in seeds:\n",
    "#             if seed in doc:\n",
    "#                 boosted_doc.extend([seed] * 10)  # Repeat seed words to increase their frequency\n",
    "#     boosted_documents.append(boosted_doc)\n",
    "\n",
    "# Create a dictionary and corpus\n",
    "# dictionary = Dictionary(boosted_documents)\n",
    "# corpus = [dictionary.doc2bow(doc) for doc in boosted_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA\n",
    "lda = LdaModel(corpus=corpus, \n",
    "               id2word=dictionary, \n",
    "               num_topics=len(seed_words), \n",
    "               passes=15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 6: 0.011*\"*\" + 0.003*\"gobierno_2024-2028\" + 0.003*\"adn\" + 0.002*\"canton.\" + 0.002*\"proyectos\" + 0.002*\"canton\" + 0.002*\"desarrollo\" + 0.002*\"gestion\" + 0.001*\"cantonal\" + 0.001*\"municipalidad\"\n",
      "Topic 17: 0.004*\"jesus_alcalde\" + 0.003*\"-\" + 0.003*\"*\" + 0.002*\"canton\" + 0.001*\"km_-\" + 0.001*\"coordinacion\" + 0.001*\"estrategias\" + 0.001*\"*_apoyo\" + 0.001*\"-_coordinar\" + 0.001*\"comunidades\"\n",
      "Topic 19: 0.004*\"-\" + 0.002*\"municipalidad\" + 0.002*\"ministerio\" + 0.002*\"objetivo_lineas\" + 0.002*\"san_mateo.\" + 0.002*\"accion_responsables\" + 0.001*\"-_coordinar\" + 0.001*\"plan_gob\" + 0.001*\"ierno_2024-2028\" + 0.001*\"mejorar\"\n",
      "Topic 23: 0.003*\"canton\" + 0.003*\"desarrollo\" + 0.002*\"grecia\" + 0.002*\"mas\" + 0.002*\"liberia\" + 0.002*\"canton.\" + 0.002*\"municipalidad\" + 0.002*\"gestion\" + 0.002*\"nicoya\" + 0.002*\"municipal\"\n",
      "Topic 30: 0.003*\"*\" + 0.003*\"canton\" + 0.002*\"!rio_cuarto\" + 0.002*\"*_implementar\" + 0.002*\"pasj_puertas\" + 0.002*\"gobierno_-\" + 0.002*\"alianza_san\" + 0.002*\"abiertas_plan\" + 0.002*\"jose_2024-2028\" + 0.002*\"avanza!\"\n",
      "Topic 20: 0.000*\"canton\" + 0.000*\"*\" + 0.000*\"desarrollo\" + 0.000*\"mas\" + 0.000*\"asi\" + 0.000*\"municipal\" + 0.000*\"canton.\" + 0.000*\"seguridad\" + 0.000*\"municipalidad\" + 0.000*\"personas\"\n",
      "Topic 26: 0.008*\"*\" + 0.003*\"canton\" + 0.003*\"tecnica_comision\" + 0.003*\"proyecto\" + 0.003*\"plan_gobierno\" + 0.002*\"evaluacion.\" + 0.002*\"municipal\" + 0.002*\"presupuesto_municipal.\" + 0.002*\"mas\" + 0.002*\"comision_evaluacion.\"\n",
      "Topic 5: 0.003*\"asi\" + 0.003*\"!somos_puerto\" + 0.003*\"jimenez,_decidimos\" + 0.002*\"canton_puerto\" + 0.002*\"canton\" + 0.002*\"tres_distritos\" + 0.002*\"juntos!\" + 0.001*\"ello\" + 0.001*\"jimenez_*\" + 0.001*\"objetivo_estrategico:\"\n",
      "Topic 15: 0.004*\"canton\" + 0.004*\"desarrollo\" + 0.003*\"municipal\" + 0.002*\"municipalidad\" + 0.002*\"asi\" + 0.002*\"mas\" + 0.002*\"*\" + 0.002*\"canton.\" + 0.002*\"-\" + 0.002*\"personas\"\n",
      "Topic 12: 0.008*\"plan_gobierno\" + 0.004*\"2024-2028_hagamoslo\" + 0.004*\"2024-_2028\" + 0.004*\"segura_alcaldesa\" + 0.004*\"patricia_porras\" + 0.004*\"municipalidad_aserri\" + 0.003*\"acciones\" + 0.002*\"canton.\" + 0.002*\"canton\" + 0.002*\"juntos\"\n",
      "Topic 24: 0.004*\"pagina_|\" + 0.004*\"cantidad\" + 0.003*\"coordinacion\" + 0.003*\"desarrollo\" + 0.002*\"anualmente.\" + 0.002*\"municipales\" + 0.002*\"porcentaje\" + 0.002*\"plan\" + 0.002*\"cantonal\" + 0.002*\"cantidad_planes\"\n",
      "Topic 10: 0.008*\"*\" + 0.003*\"meta_indicador\" + 0.003*\"objetivo_especifico\" + 0.003*\"responsable_(s)\" + 0.003*\"municipal_afectado\" + 0.003*\"22_partido\" + 0.003*\"unidad_social\" + 0.002*\"puriscal\" + 0.002*\"gestion_vial.\" + 0.002*\"gestion\"\n",
      "Topic 8: 0.009*\"*\" + 0.003*\"mas_mejor\" + 0.002*\"canton\" + 0.002*\"adi\" + 0.002*\"*_ley\" + 0.002*\"guatuso\" + 0.002*\"desarrollo\" + 0.002*\"municipalidad_guatuso\" + 0.002*\"progresista_plan\" + 0.002*\"guatuso_2024\"\n",
      "Topic 22: 0.005*\"valores_santo\" + 0.005*\"familias,_construyendo\" + 0.004*\"social_costarricense\" + 0.004*\"partido_justicia\" + 0.004*\"-_santo\" + 0.004*\"domingo\" + 0.003*\"domingo.\" + 0.001*\"canton\" + 0.001*\"moravia\" + 0.001*\"domingo._*\"\n",
      "Topic 25: 0.005*\"*\" + 0.004*\"canton\" + 0.004*\"plan_gobierno\" + 0.003*\"2024-2028_pagina\" + 0.003*\"desarrollo\" + 0.003*\"objetivo_proyecto:\" + 0.003*\"canton.\" + 0.003*\"municipal_matina\" + 0.002*\"*_meta:\" + 0.002*\"mas\"\n",
      "Topic 13: 0.003*\"proyectos\" + 0.002*\"canton\" + 0.002*\"justa\" + 0.002*\"talamanca_mas\" + 0.002*\"24\" + 0.002*\"municipal\" + 0.002*\"puriscal\" + 0.001*\"lograr_propuesto\" + 0.001*\"acciones_a)\" + 0.001*\"acciones_destacadas\"\n",
      "Topic 31: 0.004*\"gobierno_local\" + 0.003*\"canton_esparza\" + 0.003*\"*\" + 0.003*\"2024-2028\" + 0.002*\"-_eje\" + 0.002*\"areas_crecimiento\" + 0.002*\"canton\" + 0.002*\"mediante\" + 0.001*\"desarrollo\" + 0.001*\"cada\"\n",
      "Topic 27: 0.002*\"gobierno_2024-2028\" + 0.001*\"participacion_colaboracion\" + 0.001*\"municipalidad_turrialba\" + 0.001*\"objetivo\" + 0.001*\"justicia_social,\" + 0.001*\"(estatuto_partido\" + 0.001*\"ostenta\" + 0.001*\"enfoques\" + 0.001*\"social_cristiana,\" + 0.001*\"persona_humana,\"\n",
      "Topic 28: 0.012*\"#\" + 0.008*\"CL\" + 0.001*\"municipalidad_poas\" + 0.001*\"2024-2028._trabajando\" + 0.001*\"pjsc._plan\" + 0.001*\"justicia_social\" + 0.001*\"#_desarrollar\" + 0.001*\"1.\" + 0.001*\"carrillos\" + 0.001*\"canton._#\"\n",
      "Topic 18: 0.002*\"gobierno_alcaldia\" + 0.002*\"2028_plan\" + 0.002*\"municipal\" + 0.002*\"ano.\" + 0.002*\"construccion\" + 0.001*\"canton.\" + 0.001*\"numero_acciones\" + 0.001*\"canton\" + 0.001*\"desarrollo\" + 0.001*\"local\"\n"
     ]
    }
   ],
   "source": [
    "# Display topics\n",
    "topics = lda.print_topics()\n",
    "for topic_id, topic in topics:\n",
    "    print(f\"Topic {topic_id}: {topic}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
