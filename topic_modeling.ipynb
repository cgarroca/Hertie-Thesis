{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\carme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\carme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# for first part\n",
    "\n",
    "import pandas as pd\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import numpy as np\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel, CoherenceModel\n",
    "import re\n",
    "import unidecode\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "#download puntuation and stopwords\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "#additional for second part\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install Unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310, 10)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/carme/Dropbox/MIO/DOCS/Hertie/Thesis/Hertie-Thesis/Data/clean_data.csv')\n",
    "# 'C:/Users/carme/Dropbox/MIO/DOCS/Hertie/Thesis/Elecciones_Municipales_2024/clean_data.csv'\n",
    "#filter column with na values\n",
    "plans = data.copy().dropna()\n",
    "plans = plans.reset_index(drop=True)\n",
    "plans.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the one duplicate value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encontrar duplicados en 'clean_text'\n",
    "duplicated_texts = plans['clean_text'][plans['clean_text'].duplicated(keep=False)]\n",
    "\n",
    "# Mostrar los documentos duplicados\n",
    "# print(duplicated_texts)\n",
    "\n",
    "# plans.loc[303,'clean_text']\n",
    "plans.at[303,'clean_text'] = float(\"NaN\")\n",
    "# plans.loc[303,'clean_text']\n",
    "plans = plans.dropna()\n",
    "plans.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    El ambiente nos importa\\r\\nLa preservacion del...\n",
      "1        A Quienes Habitan Alajuela\\r\\n    Alajuela...\n",
      "2                            PROGRAMA DE GOBIERNO\\r...\n",
      "3         PLAN DE GOBIERNO 2024 - 2028 | KATHIA ARR...\n",
      "4    DESARROLLO\\r\\nECONOMICO..........................\n",
      "Name: clean_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#remove accents from spanish words\n",
    "def remove_accents(text):\n",
    "    return unidecode.unidecode(text)\n",
    "\n",
    "plans['clean_text'] = plans['clean_text'].apply(remove_accents)\n",
    "\n",
    "print(plans['clean_text'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete loose letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función para limpiar el texto\n",
    "def limpiar_texto(texto):\n",
    "    # Eliminar palabras de una sola letra que no sean 'a' o 'I' (ajustar según tu criterio)\n",
    "    texto_limpio = re.sub(r'\\b(?<!\\b[aAiI]\\b)[a-zA-Z]\\b', '', texto)\n",
    "    return texto_limpio\n",
    "\n",
    "# Aplicar la función a cada elemento de la columna de texto\n",
    "plans['clean_text'] = plans['clean_text'].apply(limpiar_texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plans['clean_text'] = plans['clean_text'].lower()\n",
    "plans['clean_text']=[text.lower() for text in plans['clean_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete province, canton and name of candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para eliminar palabras de las columnas especificadas de 'clean_text'\n",
    "def remove_words(row, column_names):\n",
    "    text = row['clean_text']\n",
    "    for column in column_names:\n",
    "        # Obtener palabras del campo actual, dividiendo por espacio o guión bajo\n",
    "        # La expresión regular [ _] significa \"espacio o guión bajo\"\n",
    "        # Usar str.lower() para convertir el texto a minúsculas antes de dividirlo\n",
    "        words = re.split(r'[ _]', str(row[column]).lower())\n",
    "        # Eliminar cada palabra, en sus diferentes formas de capitalización, del texto\n",
    "        for word in words:\n",
    "            text = re.sub(r'\\b' + re.escape(word) + r'\\b', '', text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "    # Columnas de las cuales se eliminarán las palabras en 'clean_text'\n",
    "columns_to_remove = ['Provincia', 'Municipalidad', 'Partido', 'Candidato']\n",
    "\n",
    "# plans['clean_text'] = plans.apply(remove_words, column_names=columns_to_remove, axis=1)\n",
    "plans.loc[:, 'clean_text'] = plans.apply(lambda row: remove_words(row, columns_to_remove), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('spanish'))\n",
    "# Take accents from stopwords\n",
    "stop_words = {unidecode.unidecode(word) for word in stop_words}\n",
    "\n",
    "# Lista de palabras personalizadas para agregar\n",
    "custom_stop_words = [\n",
    "    'ana imelsa guzman espinoza','junnier a salazar tobal','claudia quintanilla tartaglione',\n",
    "    'accion',\n",
    "    'alajuelense', 'alcalde', 'alcalde', 'alcaldesa', 'alcaldia', 'alcaldia', 'ambito', 'anexo', 'anterior', 'apoyaremos', 'aqui',\n",
    "    'brenes', 'busca', 'busca', \n",
    "    'cabo', 'cabo', 'canaza', 'candidata','canton', 'carara', 'caso', 'cion', 'cl', 'continuar', 'continuar', 'coordinaremos', 'cosas', 'crearemos', \n",
    "    'cuales', 'cuanto', 'cuanto', 'cuatro', \n",
    "    'debemos', 'debemos', \n",
    "    'elena', 'enrique', 'etc', 'etc', \n",
    "    'fomentaremos', 'formato', \n",
    "    'gestionaremos', 'golfito', 'guayabo', \n",
    "    'hagamoslo', 'haremos', \n",
    "    'ii', 'implementaremos', 'incluyendo', 'indicador',\n",
    "    'juntos', \n",
    "    'kathia arroyo', \n",
    "    'linea', 'lineas', 'llevar', \n",
    "    'maria', 'meta', \n",
    "    'ndeg', 'numero',\n",
    "    'objetivo', \n",
    "    'pagina', 'partir', 'periodo', 'permitira', 'pilar', 'plan de gobierno', 'poas', 'poasena', 'porcentaje', 'posible', 'posteriormente', \n",
    "    'primer', 'primera', 'promoveremos', 'proponemos', 'provincia', 'programa de gobierno','porque liberia debe avanzar',\n",
    "    'responde', 'rodriguez', \n",
    "    'sa', 'samara', 'san', 'seccion', 'sino',\n",
    "    'tabarcia', 'tal', 'tales', 'trabajaremos', 'tres', 'tribunal interno de elecciones',\n",
    "    'vamos', 'vamos', 'ver',\n",
    "    \"ejecutarlo\", \"nombre\", \"finalidad\", \"complementado\", \"instrumento\", \"debera\", \"fondos\", \"asegurar\",\n",
    "    \"verdes\", \"clave\", \"practicas\", \"potenciar\", \"asegurar\", \"habilidades\", \"ejes\", \"especial\", \"pueden\", \"nuevo\", \"asegurar\",\n",
    "    \"metas\", \"tipo\", \"permanente\", \"falta\" ,\"requiere\", \"atenienses\", \"rapidos\", \"ateniense\", \"empiecen\", \"impulso\", \"conlleva\", \"validar\",\n",
    "    \"colectivamente\", \"presta\", \"comprende\", \"orden\", \"anchas\", \"intereses\" , \"poner\", \"mencionamos\" , \"potenciar\", \"vote papeletas\", \"limonense\",\n",
    "    \"creara\", \"rio_blanco\", \"limonenses\", \"resultados\", \"resumen\", \"iniciativa\", \"asegurando\", \"clave\", \"asegurar\", \"fecha\", \"descritos\",\n",
    "    \"indicadores\", \"estrategico\", \"avanza\", \"continuaremos\", \"asimismo\", \"santa\", \"dia\", \"gracias\", \"realizadas\", \"aprovechamiento\", \"dad\", \"nes\",\n",
    "    \"impulsaremos\", \"buscaremos\", \"des\", \"municipes\", \"tos\", \"desarrollaremos\", \"pavones\", \"elecciones\", \"esparcimiento\", \"realizacion\", \"total\",\n",
    "    \"nuevo\", \"falta\", \"debido\", \"impulsaremos\", \"rutinario\", \"estrategicas\", \"menciona\", \"pag\", \"escazucenos\", \"rafael\", \"tes\", \"aportado\",\n",
    "    \"sirviendo\", \"pusc\", \"propone\", \"merecemos\", \"construyendo\", \"tienden\", \"siempre\", \"ameriten\", \"requeriran\", \"treinta\", \"beneficiado\", \"cuento\",\n",
    "    \"bicentenario\"]\n",
    "\n",
    "\n",
    "# Agregar las palabras personalizadas al conjunto de stopwords\n",
    "stop_words.update(custom_stop_words)\n",
    "\n",
    "#preprocess and stemming\n",
    "# def preprocess(text):\n",
    "#     return [word for word in word_tokenize(text.lower()) if word.\n",
    "#             isalpha() and word not in stop_words]\n",
    "\n",
    "# Spanish stemmer from Snowball\n",
    "stemmer = SnowballStemmer(\"spanish\")\n",
    "\n",
    "#with stemming and preprocessing\n",
    "def preprocess(text):\n",
    "    # Normalize and remove non-alpha characters\n",
    "    text = unidecode.unidecode(text.lower())\n",
    "    text = re.sub(r'[^a-z ]+', '', text)\n",
    "    # Tokenize, remove stopwords, and stem\n",
    "    tokens = word_tokenize(text)\n",
    "    # return ' '.join(stemmer.stem(word) for word in tokens if word not in stop_words) #with stemmer\n",
    "    return ' '.join(word for word in tokens if word not in stop_words) #with no stemmer\n",
    "\n",
    "plans['processed_text'] = plans['clean_text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Construir modelos de bigramas y trigramas\n",
    "# bigram = Phrases(processed_docs, min_count=10, threshold=10)  # Ajusta los parámetros según sea necesario\n",
    "# bigram_mod = Phraser(bigram)\n",
    "\n",
    "# # Aplicar el modelo para construir bigramas\n",
    "# bigram_texts = [bigram_mod[doc] for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Crear el diccionario y el corpus para LDA\n",
    "# dictionary = Dictionary(bigram_texts)\n",
    "# dictionary.filter_extremes(no_below=2, no_above=0.5)\n",
    "# corpus = [dictionary.doc2bow(doc) for doc in bigram_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary and corpus for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary = Dictionary(processed_docs)\n",
    "# dictionary.filter_extremes(no_below=2, no_above=0.5)\n",
    "# corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA: Training and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_topics = 150  # Ajusta este número según tus necesidades\n",
    "# lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, passes=15)\n",
    "\n",
    "# for i, topic in lda_model.show_topics(formatted=True, num_topics=num_topics, num_words=10):\n",
    "#     print(f'Tema {i}: {topic}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not great. Possible reasons:\n",
    "+ lengths of documents are very different\n",
    "+ the docs are not very different between each other\n",
    "\n",
    "# Using TF-IDF. Otherwise we can try doing a Guided LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic  0\n",
      "[('pensando grande', 0.3898240245831482), ('local areas', 0.2746915758651164), ('tacares', 0.21332041482546377), ('per capita', 0.20612819141733754), ('tasa mortalidad', 0.1993133864272263), ('capita', 0.19591388576373264), ('sarchi', 0.1891577129161759), ('municipaleje', 0.18012359259700947), ('ademas hacer', 0.17133341427346585), ('trabajo comites', 0.1711722166512821)]\n",
      "Topic  1\n",
      "[('social sector', 0.3050498240820449), ('proseguir', 0.24253651599245704), ('relanzar', 0.24072843663065366), ('cana', 0.2218025050439511), ('bienestar salud', 0.22017070618617077), ('eje economico', 0.2064935574100022), ('muni digital', 0.19857939930665464), ('juegos comunales', 0.19527243440101266), ('cantonalse', 0.192020692004463), ('sistema computo', 0.18830660998235196)]\n",
      "Topic  2\n",
      "[('evaluar', 1.6546902462587814), ('plp', 1.30532230318389), ('ultimos', 1.2248284407700392), ('promueve', 1.1070170275110451), ('satisfaccion', 1.029185280059857), ('jose', 0.9960766349660064), ('continuo', 0.948940096084766), ('transformar', 0.9417496639136116), ('regular', 0.9124411860266799), ('expertos', 0.9094992180866852)]\n",
      "Topic  3\n",
      "[('millones', 1.0925152432445189), ('francas', 0.9789045934641124), ('zonas francas', 0.9525444773494753), ('gestion vial', 0.8884080575626595), ('socio', 0.8285896494952897), ('emocional', 0.8265468405106889), ('juridica', 0.8115159407725474), ('orientadas', 0.7961846138206162), ('dinamica', 0.7818296282979216), ('mundial', 0.7635665596692434)]\n",
      "Topic  4\n",
      "[('ods', 1.5148361055765394), ('productivo', 1.262096510514617), ('acceso servicios', 1.2582515176484572), ('responsables', 1.0890632148877653), ('iii', 0.9346094573165178), ('inclusivos', 0.9088798257272802), ('politica publica', 0.9070322457595781), ('favor', 0.9038367564612105), ('impulsar desarrollo', 0.8508805975919906), ('posicion', 0.8485946839057982)]\n",
      "Topic  5\n",
      "[('programade', 0.5443192178766812), ('ra', 0.4461663241153558), ('ro', 0.3847058756306498), ('re', 0.26828807830171314), ('fo', 0.21631575217912571), ('huetar', 0.2141075364792896), ('laeficiencia eficacia', 0.2128490360579572), ('estrategias implementar', 0.21018540853443823), ('aduana', 0.2081071459169087), ('laeficiencia', 0.20256592064714649)]\n",
      "Topic  6\n",
      "[('quesada', 0.3561993337578733), ('acoso sexual', 0.28153954548494964), ('once', 0.2329050387736196), ('vice', 0.21373901694734096), ('once distritos', 0.20923870270994882), ('alta demanda', 0.19964914885297844), ('depto', 0.19863350086064416), ('funcionando', 0.19667219271750067), ('caminos publicos', 0.19170014074331723), ('zmt', 0.19123291891710803)]\n",
      "Topic  7\n",
      "[('responsable municipal', 0.39784218701558327), ('municipal afectado', 0.37639647395547493), ('plan desarrollar', 0.34228923207617223), ('pnp', 0.2650509223968447), ('ilustracion', 0.2518066066343345), ('bataan', 0.23399650626733104), ('sosteniblesobjetivo', 0.21686185213852704), ('carrandi', 0.18958900274222404), ('industriales zonas', 0.18441239397211923), ('presente eje', 0.1811900086445855)]\n",
      "Topic  8\n",
      "[('pnp', 0.42141244746972706), ('anos anos', 0.22954742264935954), ('realizar menos', 0.18553182737760082), ('componentes claves', 0.1595870194754274), ('situacion riesgo', 0.13055978568801038), ('evaluen', 0.11915490131127462), ('belemitas', 0.11460065343639544), ('construccion programas', 0.1114857326276025), ('categoria delictiva', 0.10907533494069022), ('delictiva cantidad', 0.10907533494069022)]\n",
      "Topic  9\n",
      "[('departamento', 1.418395519261567), ('biodiversidad', 1.360070853136062), ('carreteras', 1.3199055027834068), ('equipamiento', 1.2960998913300101), ('junta', 1.2784962812865561), ('transformacion', 1.273005699709873), ('desastres', 1.1943420058856749), ('inmediata', 1.170921558944128), ('medica', 1.1357618872788997), ('promocionar', 1.1295625557394837)]\n",
      "Topic  10\n",
      "[('municipalidad plan', 0.37871769073165623), ('salon comunal', 0.3768760504181983), ('gobierno version', 0.25873560383257965), ('meses gestion', 0.23959370368907912), ('grupos trabajo', 0.23634305354892027), ('energetico', 0.21870929006620368), ('parritena', 0.2041358344814864), ('depto', 0.20255968981836595), ('fraccion', 0.19755092581695552), ('escuelas colegio', 0.19452203199821902)]\n",
      "Topic  11\n",
      "[('propuesta establecer', 0.24833634488944298), ('propuesta implementar', 0.2152005688903193), ('tendiente', 0.19497798671619385), ('contenidas', 0.16159517446101618), ('plan acciones', 0.15995684637384922), ('general implementar', 0.15035288007663355), ('vincularlas', 0.14207401088611024), ('municipal estrategias', 0.14207400851377083), ('minuciosamente', 0.14207400490556893), ('analizadas', 0.1420739999023482)]\n",
      "Topic  12\n",
      "[('mil', 0.651038444925065), ('degobierno', 0.6066882104270064), ('ejecutados', 0.5928575801172256), ('fi', 0.5176352090141356), ('corrientes', 0.4917886628836007), ('programa degobierno', 0.4616428358127763), ('municipalidad altura', 0.45421866283890233), ('formacion profesional', 0.42860349141553394), ('elementos estrategicos', 0.4068874714756904), ('lider', 0.3893452505385933)]\n",
      "Topic  13\n",
      "[('caminos', 2.726535220946202), ('animal', 2.6788824211398308), ('plazo', 2.6637800862731074), ('datos', 2.3483665346471727), ('impuestos', 2.066425207449126), ('alianza', 1.854759465362921), ('anual', 1.7865129693240318), ('principal', 1.7433722210161267), ('propiciar', 1.741485792525628), ('diversidad', 1.649945628439145)]\n",
      "Topic  14\n",
      "[('gestion', 14.345515801786899), ('gobierno', 14.14637229976298), ('municipalidad', 13.377551681537057), ('personas', 13.24220847914539), ('servicios', 11.599240529441667), ('promover', 11.329837709979826), ('programas', 10.716583617247489), ('proyectos', 10.619471212237405), ('local', 10.272463433673279), ('recursos', 9.877309641299425)]\n",
      "Topic  15\n",
      "[('gobierno municipal', 3.9786574590297663), ('tener', 3.196612540415932), ('poder', 3.1342887887985595), ('evaluacion', 2.969148698020949), ('propuestas', 2.8644529065538054), ('tiempo', 2.862105822833058), ('menos', 2.6916420363606197), ('siguientes', 2.689282805008018), ('animales', 2.6371451190810133), ('instituto', 2.624108425202384)]\n",
      "Topic  16\n",
      "[('establecer sistema', 0.4109490130396475), ('siguientes estrategias', 0.2735490708955095), ('gobernanza municipal', 0.24974037382524245), ('sistema seguimiento', 0.24407819786961835), ('plan gobernanza', 0.23879173957144334), ('realizar seguimiento', 0.22346958673082784), ('general mejorar', 0.20988067974525515), ('lograr proyectos', 0.19408054290219234), ('jerarcas', 0.1911426066119742), ('va hacer', 0.1827580366627579)]\n",
      "Topic  17\n",
      "[('propuestaseje', 0.3012874975235815), ('camino progreso', 0.24425706661867114), ('estudiantes puedan', 0.19718963044240803), ('area construccion', 0.18666751509726537), ('podria ser', 0.1808930894288581), ('servicios forma', 0.17485467092342608), ('personas alajuelenses', 0.17282595279881877), ('ess', 0.1703188531866518), ('buscamos mejorar', 0.1693114260653339), ('norte sur', 0.1676055508874302)]\n",
      "Topic  18\n",
      "[('grupo trabajo', 0.30520020149870686), ('lic', 0.25980545973331653), ('politica plan', 0.22574320374831774), ('casapresidencial', 0.21105132364630505), ('ict canatur', 0.20278381951639088), ('volver ser', 0.20132516510098727), ('puente entrada', 0.1992853742072568), ('oportunidadesinversion', 0.19084024570336702), ('elaprovechamiento recursos', 0.19084023251687804), ('ambientalproteccion', 0.19084023247792517)]\n",
      "Topic  19\n",
      "[('elementos especificos', 0.8212389503262356), ('mipymes', 0.626821212626862), ('reforma', 0.6159954008784793), ('salon', 0.5696985468491007), ('otorgar', 0.5653082141811169), ('semestre', 0.5241449211617659), ('desarrollos', 0.4869197034011541), ('horario', 0.48272033136722836), ('comportamiento', 0.4647987021695991), ('gestion institucional', 0.46064545567305026)]\n",
      "Topic  20\n",
      "[('programacion', 1.2775160685575886), ('humana', 1.0065387441428875), ('vista', 0.9012084033575021), ('algun', 0.8669849459309364), ('envejecimiento', 0.8242127252770595), ('recursos humanos', 0.7255610616830077), ('progresa', 0.6823322551235222), ('hacerlo', 0.6364527005028093), ('accidentes', 0.5873852700120983), ('enlas', 0.5781323864397766)]\n",
      "Topic  21\n",
      "[('podemos hacerlo', 0.3391714847977624), ('pregunta', 0.32966870432471446), ('gobierno programa', 0.3296150236605909), ('gobierno debe', 0.2907606365525677), ('mil personas', 0.26664797185923705), ('cumplimiento revision', 0.24800410067889395), ('convenios cooperativos', 0.19417947328760843), ('articulacion estrategica', 0.1911829841460222), ('debe avanzar', 0.165895243572933), ('municipalplan', 0.14066838184411204)]\n",
      "Topic  22\n",
      "[('gobierno version', 0.4030499487582533), ('destacadas', 0.23652221436548404), ('caminos calles', 0.2282991359536747), ('ss', 0.2186635016668764), ('cahuita', 0.198231582830213), ('destaque', 0.19493389222150267), ('capacidad disfrutar', 0.1584514529310884), ('amplia capacidad', 0.1584514529310884), ('comision compuesta', 0.14962139794292967), ('distrito cahuita', 0.14906966964070273)]\n",
      "Topic  23\n",
      "[('ifam', 0.9058750479944635), ('organizaciones sociales', 0.8148285902047547), ('eje desarrollo', 0.7802417280696097), ('personas mayores', 0.7109081583381199), ('historica', 0.677848386219141), ('colon', 0.6665917184065806), ('vida poblacion', 0.6334623444244729), ('recomendaciones', 0.6200333463085373), ('apego', 0.6187900235701269), ('to', 0.559552262947139)]\n",
      "Topic  24\n",
      "[('jaco', 0.16777306698232541), ('herradura', 0.15901608464246075), ('lagunillas', 0.14782850707053413), ('transformadora', 0.12705682053673845), ('mariscos', 0.12649451951281626), ('mediante busqueda', 0.12297538215067394), ('descansar', 0.1199484185605279), ('resi', 0.11808992384994324), ('miercoles', 0.11780881900702125), ('uruguay', 0.11570070051866777)]\n",
      "Topic  25\n",
      "[('medira', 0.3001784161874358), ('exito proyecto', 0.24583091018781938), ('detallan continuacion', 0.19604440883684823), ('anos gobierno', 0.19166962637953475), ('sigma', 0.17690386604552083), ('six', 0.17690386604552083), ('six sigma', 0.17690386604552083), ('lean six', 0.17690386604552083), ('propuestas eje', 0.17658258809703428), ('lean', 0.169264689128607)]\n",
      "Topic  26\n",
      "[('opcion gente', 0.5567983286432013), ('hagamos', 0.41796983244896424), ('programa municipalidad', 0.29898901889110363), ('hagamos sucedan', 0.2513115549531279), ('sucedan', 0.23156186402596443), ('suscribir', 0.15986022733359312), ('siguiente acciones', 0.14964074683158593), ('gente gestion', 0.14022899011237397), ('desarrollara siguiente', 0.13299580416424853), ('capa asfaltica', 0.11302986104055793)]\n",
      "Topic  27\n",
      "[('pa', 0.4383568676158026), ('on', 0.3429852379872556), ('zo', 0.3398700897541093), ('ej', 0.3374800677317082), ('cia', 0.29732313990773057), ('palmareno', 0.24573801163324188), ('caficultura', 0.24114828753239856), ('desamparadeno', 0.22147789055897626), ('proyectos tarifas', 0.21596345647878465), ('objetivos proyectos', 0.1953030953642574)]\n",
      "Topic  28\n",
      "[('dimension', 0.48947511733928784), ('garantizara', 0.44110073485152534), ('pam', 0.3666692628334964), ('opcion gente', 0.35404369146417536), ('traves campanas', 0.32603904363259706), ('descarbonizacion', 0.3193062505643018), ('mensual', 0.3131817103544682), ('margenes', 0.30989867920169484), ('apoyo emprendimientos', 0.28630250374863003), ('marzo', 0.2781324925377657)]\n",
      "Topic  29\n",
      "[('instruir', 0.5724192106619297), ('munici', 0.28955708670876684), ('publi', 0.2778644952047239), ('aten', 0.26820613123382747), ('cos', 0.22859467036719197), ('vas', 0.21677303234315634), ('progreso humano', 0.20726867157750023), ('empre', 0.18830828273960973), ('palidad', 0.1882148118227723), ('espa', 0.18526296878207613)]\n"
     ]
    }
   ],
   "source": [
    "# Initialize a TF-IDF Vectorizer\n",
    "# The ngram_range parameter is set to (1, 2) to include both unigrams and bigrams\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, ngram_range=(1, 2))\n",
    "\n",
    "# Transform the texts into a document-term matrix\n",
    "dtm = tfidf_vectorizer.fit_transform(plans['processed_text'])\n",
    "\n",
    "# Initialize and fit LDA\n",
    "lda = LatentDirichletAllocation(n_components=30, random_state=0)\n",
    "lda.fit(dtm)\n",
    "\n",
    "# Function to print the topics and their top words\n",
    "def print_topics(model, vectorizer, top_n=10):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic \", idx)\n",
    "        print([(vectorizer.get_feature_names_out()[i], topic[i])\n",
    "               for i in topic.argsort()[:-top_n - 1:-1]])\n",
    "\n",
    "print_topics(lda, tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alles over again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.matutils import Sparse2Corpus\n",
    "from gensim.models.ldamodel import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convert Sparse Matrix to Gensim's Corpus\n",
    "corpus = Sparse2Corpus(dtm, documents_columns=False)  # dtm is the document-term matrix from Scikit-Learn TF-IDF in the previous chunk\n",
    "\n",
    "# Step 2: Create Dictionary object that maps IDs to words\n",
    "id2word = corpora.Dictionary()\n",
    "id2word.token2id = tfidf_vectorizer.vocabulary_\n",
    "id2word.id2token = {v: k for k, v in tfidf_vectorizer.vocabulary_.items()}\n",
    "\n",
    "# Since the vocabulary_ of TfidfVectorizer does not preserve order, we need to sort it\n",
    "sorted_vocab = sorted(tfidf_vectorizer.vocabulary_.items(), key=lambda x: x[1])\n",
    "id2word.token2id = {key: val for key, val in sorted_vocab}\n",
    "id2word.id2token = {val: key for key, val in sorted_vocab}\n",
    "\n",
    "# Note: This assumes you can tokenize your texts in the same way they were tokenized for the original LDA\n",
    "lda_gensim = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    num_topics=10,\n",
    "    random_state=0,\n",
    "    passes=10,\n",
    "    alpha='auto',\n",
    "    eta='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "0.000*\"gestion\" + 0.000*\"servicios\" + 0.000*\"municipalidad\" + 0.000*\"personas\" + 0.000*\"promover\" + 0.000*\"gobierno\" + 0.000*\"programas\" + 0.000*\"educacion\" + 0.000*\"recursos\" + 0.000*\"apoyo\"\n",
      "\n",
      "\n",
      "Topic 1:\n",
      "0.000*\"io\" + 0.000*\"municipalidad\" + 0.000*\"personas\" + 0.000*\"gobierno\" + 0.000*\"promover\" + 0.000*\"espacios\" + 0.000*\"gestion\" + 0.000*\"proyectos\" + 0.000*\"poblacion\" + 0.000*\"actividades\"\n",
      "\n",
      "\n",
      "Topic 2:\n",
      "0.000*\"gestion\" + 0.000*\"gobierno\" + 0.000*\"promover\" + 0.000*\"municipalidad\" + 0.000*\"proyectos\" + 0.000*\"personas\" + 0.000*\"local\" + 0.000*\"servicios\" + 0.000*\"poblacion\" + 0.000*\"cantonal\"\n",
      "\n",
      "\n",
      "Topic 3:\n",
      "0.000*\"gobierno\" + 0.000*\"municipalidad\" + 0.000*\"gestion\" + 0.000*\"servicios\" + 0.000*\"personas\" + 0.000*\"plan gobierno\" + 0.000*\"eje\" + 0.000*\"promover\" + 0.000*\"recursos\" + 0.000*\"mejorar\"\n",
      "\n",
      "\n",
      "Topic 4:\n",
      "0.001*\"gestion\" + 0.001*\"gobierno\" + 0.001*\"municipalidad\" + 0.001*\"personas\" + 0.001*\"servicios\" + 0.001*\"promover\" + 0.001*\"programas\" + 0.001*\"proyectos\" + 0.001*\"local\" + 0.001*\"recursos\"\n",
      "\n",
      "\n",
      "Topic 5:\n",
      "0.000*\"gobierno\" + 0.000*\"municipalidad\" + 0.000*\"programas\" + 0.000*\"personas\" + 0.000*\"social\" + 0.000*\"local\" + 0.000*\"programas gobierno\" + 0.000*\"promover\" + 0.000*\"municipales programas\" + 0.000*\"gestion\"\n",
      "\n",
      "\n",
      "Topic 6:\n",
      "0.000*\"gobierno\" + 0.000*\"servicios\" + 0.000*\"gestion\" + 0.000*\"programa\" + 0.000*\"asi\" + 0.000*\"municipalidad\" + 0.000*\"personas\" + 0.000*\"infraestructura\" + 0.000*\"social\" + 0.000*\"proyectos\"\n",
      "\n",
      "\n",
      "Topic 7:\n",
      "0.000*\"pa\" + 0.000*\"zo\" + 0.000*\"ej\" + 0.000*\"ambientalproteccion\" + 0.000*\"on\" + 0.000*\"familia mujer\" + 0.000*\"ict canatur\" + 0.000*\"municipal dinamica\" + 0.000*\"oportunidadesinversion\" + 0.000*\"elaprovechamiento recursos\"\n",
      "\n",
      "\n",
      "Topic 8:\n",
      "0.000*\"gestion\" + 0.000*\"municipalidad\" + 0.000*\"programas\" + 0.000*\"proyecto\" + 0.000*\"programa\" + 0.000*\"servicios\" + 0.000*\"espacios\" + 0.000*\"comunidad\" + 0.000*\"cantonal\" + 0.000*\"establecer\"\n",
      "\n",
      "\n",
      "Topic 9:\n",
      "0.000*\"gestion\" + 0.000*\"construccion\" + 0.000*\"gobierno\" + 0.000*\"servicios\" + 0.000*\"local\" + 0.000*\"promover\" + 0.000*\"mediante\" + 0.000*\"acciones\" + 0.000*\"cantonal\" + 0.000*\"poblacion\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing topics\n",
    "\n",
    "def display_topics(model, num_words=10):\n",
    "    for topic_id, topic in model.print_topics(num_topics=-1, num_words=num_words):\n",
    "        print(f\"Topic {topic_id}:\")\n",
    "        print(topic)\n",
    "        print(\"\\n\")\n",
    "\n",
    "display_topics(lda_gensim, num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carme\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\topic_coherence\\direct_confirmation_measure.py:204: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  m_lr_i = np.log(numerator / denominator)\n",
      "c:\\Users\\carme\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\topic_coherence\\indirect_confirmation_measure.py:323: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return cv1.T.dot(cv2)[0, 0] / (_magnitude(cv1) * _magnitude(cv2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score (C_V):  nan\n"
     ]
    }
   ],
   "source": [
    "# Tokenize your texts. This should match whatever tokenizer you used to prepare your DTM for LDA\n",
    "tokenized_texts = [doc.split() for doc in plans['processed_text']]  # Assuming the text is space-separated tokens\n",
    "\n",
    "# Compute Coherence Score using C_V measure\n",
    "coherence_model_lda = CoherenceModel(model=lda_gensim, texts=tokenized_texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score (C_V): ', coherence_lda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
